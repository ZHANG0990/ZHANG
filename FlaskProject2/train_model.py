#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç½‘ç»œæµé‡åˆ†ç±»æ¨¡å‹è®­ç»ƒè„šæœ¬
æ”¯æŒæ•°æ®ç”Ÿæˆã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°å’Œä¼˜åŒ–
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib
import os
from datetime import datetime, timedelta
import random
import warnings
warnings.filterwarnings('ignore')

# å¯é€‰ä¾èµ–
try:
    import xgboost as xgb
    HAS_XGBOOST = True
except ImportError:
    HAS_XGBOOST = False
    print("æç¤º: XGBoostæœªå®‰è£…ï¼Œå¯è¿è¡Œ 'pip install xgboost' å®‰è£…ä»¥è·å¾—æ›´å¥½æ€§èƒ½")

try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    HAS_PLOTTING = True
except ImportError:
    HAS_PLOTTING = False
    print("æç¤º: matplotlib/seabornæœªå®‰è£…ï¼Œå°†è·³è¿‡å¯è§†åŒ–åŠŸèƒ½")

class TrafficDataGenerator:
    """ç½‘ç»œæµé‡æ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self):
        # å¸¸è§ç«¯å£å’Œåè®®
        self.common_ports = {
            'HTTP': [80, 8080, 8000, 3000],
            'HTTPS': [443, 8443],
            'SSH': [22],
            'FTP': [21, 20],
            'DNS': [53],
            'SMTP': [25, 587],
            'POP3': [110, 995],
            'IMAP': [143, 993],
            'TELNET': [23],
            'SNMP': [161, 162]
        }
        
        # æ”»å‡»ç±»å‹å’Œç‰¹å¾
        self.attack_patterns = {
            'DDoS': {
                'packet_count_range': (10000, 100000),
                'byte_count_range': (1000000, 50000000),
                'duration_range': (1, 30),
                'protocols': ['TCP', 'UDP', 'ICMP'],
                'port_scan': False
            },
            'Port_Scan': {
                'packet_count_range': (100, 1000),
                'byte_count_range': (5000, 50000),
                'duration_range': (10, 300),
                'protocols': ['TCP'],
                'port_scan': True
            },
            'Brute_Force': {
                'packet_count_range': (50, 500),
                'byte_count_range': (2000, 20000),
                'duration_range': (60, 1800),
                'protocols': ['TCP'],
                'port_scan': False
            },
            'SQL_Injection': {
                'packet_count_range': (10, 100),
                'byte_count_range': (1000, 10000),
                'duration_range': (1, 60),
                'protocols': ['TCP'],
                'port_scan': False
            },
            'Malware': {
                'packet_count_range': (100, 2000),
                'byte_count_range': (10000, 200000),
                'duration_range': (30, 600),
                'protocols': ['TCP', 'UDP'],
                'port_scan': False
            }
        }
    
    def generate_ip(self, is_internal=True):
        """ç”ŸæˆIPåœ°å€"""
        if is_internal:
            # å†…ç½‘IP
            networks = ['192.168.', '10.', '172.16.']
            network = random.choice(networks)
            if network == '192.168.':
                return f"{network}{random.randint(1, 255)}.{random.randint(1, 254)}"
            elif network == '10.':
                return f"{network}{random.randint(1, 255)}.{random.randint(1, 255)}.{random.randint(1, 254)}"
            else:
                return f"{network}{random.randint(16, 31)}.{random.randint(1, 254)}"
        else:
            # å¤–ç½‘IP
            return f"{random.randint(1, 223)}.{random.randint(1, 255)}.{random.randint(1, 255)}.{random.randint(1, 254)}"
    
    def generate_normal_traffic(self, count):
        """ç”Ÿæˆæ­£å¸¸æµé‡æ•°æ®"""
        data = []
        
        for _ in range(count):
            protocol = random.choice(['TCP', 'UDP', 'ICMP'])
            
            # é€‰æ‹©å¸¸è§ç«¯å£
            service = random.choice(list(self.common_ports.keys()))
            dst_port = random.choice(self.common_ports[service])
            src_port = random.randint(1024, 65535)
            
            # æ­£å¸¸æµé‡ç‰¹å¾
            packet_count = random.randint(1, 1000)
            byte_count = random.randint(64, 100000)
            duration = random.uniform(0.1, 300)
            
            # è®¡ç®—è¡ç”Ÿç‰¹å¾
            packets_per_second = packet_count / max(duration, 0.1)
            bytes_per_packet = byte_count / max(packet_count, 1)
            bytes_per_second = byte_count / max(duration, 0.1)
            
            data.append({
                'timestamp': datetime.now() - timedelta(seconds=random.randint(0, 86400)),
                'src_ip': self.generate_ip(True),
                'dst_ip': self.generate_ip(random.choice([True, False])),
                'src_port': src_port,
                'dst_port': dst_port,
                'protocol': protocol,
                'packet_count': packet_count,
                'byte_count': byte_count,
                'duration': round(duration, 2),
                'packets_per_second': round(packets_per_second, 2),
                'bytes_per_packet': round(bytes_per_packet, 2),
                'bytes_per_second': round(bytes_per_second, 2),
                'is_weekend': random.choice([0, 1]),
                'hour_of_day': random.randint(0, 23),
                'label': 'Normal'
            })
        
        return data
    
    def generate_attack_traffic(self, attack_type, count):
        """ç”Ÿæˆæ”»å‡»æµé‡æ•°æ®"""
        data = []
        pattern = self.attack_patterns[attack_type]
        
        for _ in range(count):
            protocol = random.choice(pattern['protocols'])
            
            # æ”»å‡»æµé‡ç‰¹å¾
            packet_count = random.randint(*pattern['packet_count_range'])
            byte_count = random.randint(*pattern['byte_count_range'])
            duration = random.uniform(*pattern['duration_range'])
            
            # ç«¯å£æ‰«æç‰¹å¾
            if pattern['port_scan']:
                dst_port = random.randint(1, 65535)
                src_port = random.randint(1024, 65535)
            else:
                # é’ˆå¯¹å¸¸è§æœåŠ¡çš„æ”»å‡»
                service = random.choice(list(self.common_ports.keys()))
                dst_port = random.choice(self.common_ports[service])
                src_port = random.randint(1024, 65535)
            
            # è®¡ç®—è¡ç”Ÿç‰¹å¾
            packets_per_second = packet_count / max(duration, 0.1)
            bytes_per_packet = byte_count / max(packet_count, 1)
            bytes_per_second = byte_count / max(duration, 0.1)
            
            data.append({
                'timestamp': datetime.now() - timedelta(seconds=random.randint(0, 86400)),
                'src_ip': self.generate_ip(False),  # æ”»å‡»é€šå¸¸æ¥è‡ªå¤–ç½‘
                'dst_ip': self.generate_ip(True),   # ç›®æ ‡é€šå¸¸æ˜¯å†…ç½‘
                'src_port': src_port,
                'dst_port': dst_port,
                'protocol': protocol,
                'packet_count': packet_count,
                'byte_count': byte_count,
                'duration': round(duration, 2),
                'packets_per_second': round(packets_per_second, 2),
                'bytes_per_packet': round(bytes_per_packet, 2),
                'bytes_per_second': round(bytes_per_second, 2),
                'is_weekend': random.choice([0, 1]),
                'hour_of_day': random.randint(0, 23),
                'label': attack_type
            })
        
        return data
    
    def generate_dataset(self, total_samples=10000):
        """ç”Ÿæˆå®Œæ•´æ•°æ®é›†"""
        print(f"æ­£åœ¨ç”Ÿæˆ {total_samples} æ¡æµé‡æ•°æ®...")
        
        # æ•°æ®åˆ†å¸ƒï¼š70%æ­£å¸¸æµé‡ï¼Œ30%æ”»å‡»æµé‡
        normal_count = int(total_samples * 0.7)
        attack_count = total_samples - normal_count
        
        # ç”Ÿæˆæ­£å¸¸æµé‡
        data = self.generate_normal_traffic(normal_count)
        print(f"ç”Ÿæˆæ­£å¸¸æµé‡: {normal_count} æ¡")
        
        # ç”Ÿæˆå„ç§æ”»å‡»æµé‡
        attack_types = list(self.attack_patterns.keys())
        attack_per_type = attack_count // len(attack_types)
        
        for attack_type in attack_types:
            attack_data = self.generate_attack_traffic(attack_type, attack_per_type)
            data.extend(attack_data)
            print(f"ç”Ÿæˆ {attack_type} æ”»å‡»æµé‡: {attack_per_type} æ¡")
        
        # è½¬æ¢ä¸ºDataFrameå¹¶æ‰“ä¹±é¡ºåº
        df = pd.DataFrame(data)
        df = df.sample(frac=1).reset_index(drop=True)
        
        print(f"æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼Œæ€»è®¡ {len(df)} æ¡è®°å½•")
        print(f"æ ‡ç­¾åˆ†å¸ƒ:\n{df['label'].value_counts()}")
        
        return df

class AdvancedTrafficClassifier:
    """é«˜çº§ç½‘ç»œæµé‡åˆ†ç±»å™¨"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.label_encoder = LabelEncoder()
        self.feature_importance = {}
        self.best_model = None
        self.best_score = 0
        
    def load_and_preprocess_data(self, data_path=None, df=None):
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
        if df is not None:
            print("ä½¿ç”¨æä¾›çš„DataFrame...")
        else:
            print("æ­£åœ¨åŠ è½½æ•°æ®...")
            df = pd.read_csv(data_path)
        
        # å¤„ç†æ—¶é—´ç‰¹å¾
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df['hour'] = df['timestamp'].dt.hour
            df['day_of_week'] = df['timestamp'].dt.dayofweek
            df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
        
        # IPåœ°å€ç‰¹å¾å·¥ç¨‹
        if 'src_ip' in df.columns:
            df['src_ip_class'] = df['src_ip'].apply(self.get_ip_class)
            df['src_ip_private'] = df['src_ip'].apply(self.is_private_ip).astype(int)
        
        if 'dst_ip' in df.columns:
            df['dst_ip_class'] = df['dst_ip'].apply(self.get_ip_class)
            df['dst_ip_private'] = df['dst_ip'].apply(self.is_private_ip).astype(int)
        
        # ç«¯å£ç‰¹å¾
        if 'dst_port' in df.columns:
            df['is_common_port'] = df['dst_port'].apply(self.is_common_port).astype(int)
            df['port_category'] = df['dst_port'].apply(self.categorize_port)
        
        # æµé‡ç»Ÿè®¡ç‰¹å¾
        if 'packets_per_second' in df.columns:
            df['pps_log'] = np.log1p(df['packets_per_second'])
        if 'bytes_per_second' in df.columns:
            df['bps_log'] = np.log1p(df['bytes_per_second'])
        
        return df
    
    def get_ip_class(self, ip):
        """è·å–IPåœ°å€ç±»åˆ«"""
        try:
            first_octet = int(ip.split('.')[0])
            if 1 <= first_octet <= 126:
                return 'A'
            elif 128 <= first_octet <= 191:
                return 'B'
            elif 192 <= first_octet <= 223:
                return 'C'
            else:
                return 'Other'
        except:
            return 'Invalid'
    
    def is_private_ip(self, ip):
        """åˆ¤æ–­æ˜¯å¦ä¸ºç§æœ‰IP"""
        try:
            octets = ip.split('.')
            first = int(octets[0])
            second = int(octets[1])
            
            if first == 10:
                return True
            elif first == 172 and 16 <= second <= 31:
                return True
            elif first == 192 and second == 168:
                return True
            elif ip == '127.0.0.1':
                return True
            return False
        except:
            return False
    
    def is_common_port(self, port):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¸¸è§ç«¯å£"""
        common_ports = {80, 443, 22, 21, 25, 53, 110, 143, 993, 995, 587, 465}
        return port in common_ports
    
    def categorize_port(self, port):
        """ç«¯å£åˆ†ç±»"""
        if port < 1024:
            return 'system'
        elif port < 49152:
            return 'registered'
        else:
            return 'dynamic'
    
    def prepare_features(self, df):
        """å‡†å¤‡ç‰¹å¾æ•°æ®"""
        # é€‰æ‹©æ•°å€¼ç‰¹å¾
        numeric_features = ['packet_count', 'byte_count', 'duration', 
                          'packets_per_second', 'bytes_per_packet', 'bytes_per_second',
                          'hour_of_day', 'is_weekend']
        
        # é€‰æ‹©åˆ†ç±»ç‰¹å¾
        categorical_features = ['protocol', 'src_ip_class', 'dst_ip_class', 'port_category']
        
        # æ·»åŠ æ–°ç‰¹å¾
        if 'pps_log' in df.columns:
            numeric_features.append('pps_log')
        if 'bps_log' in df.columns:
            numeric_features.append('bps_log')
        if 'src_ip_private' in df.columns:
            numeric_features.append('src_ip_private')
        if 'dst_ip_private' in df.columns:
            numeric_features.append('dst_ip_private')
        if 'is_common_port' in df.columns:
            numeric_features.append('is_common_port')
        
        # å¤„ç†ç¼ºå¤±å€¼
        for feature in numeric_features:
            if feature in df.columns:
                df[feature] = df[feature].fillna(df[feature].median())
        
        # ç¼–ç åˆ†ç±»ç‰¹å¾
        for feature in categorical_features:
            if feature in df.columns:
                if feature not in self.scalers:
                    self.scalers[feature] = LabelEncoder()
                    df[feature] = self.scalers[feature].fit_transform(df[feature].astype(str))
                else:
                    df[feature] = self.scalers[feature].transform(df[feature].astype(str))
        
        # é€‰æ‹©æœ€ç»ˆç‰¹å¾
        available_features = [f for f in numeric_features + categorical_features if f in df.columns]
        X = df[available_features]
        
        return X, available_features
    
    def train_models(self, X, y):
        """è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
        print("æ­£åœ¨è®­ç»ƒå¤šä¸ªæ¨¡å‹...")
        
        # æ•°æ®æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        self.scalers['feature_scaler'] = scaler
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # å®šä¹‰æ¨¡å‹
        models = {
            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
            'GradientBoosting': GradientBoostingClassifier(random_state=42),
            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),
            'SVM': SVC(random_state=42, probability=True),
            'NeuralNetwork': MLPClassifier(random_state=42, max_iter=300)
        }
        
        # æ·»åŠ XGBoostï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if HAS_XGBOOST:
            models['XGBoost'] = xgb.XGBClassifier(random_state=42, eval_metric='mlogloss')
        
        # è®­ç»ƒå’Œè¯„ä¼°æ¯ä¸ªæ¨¡å‹
        results = {}
        for name, model in models.items():
            print(f"è®­ç»ƒ {name}...")
            
            # è®­ç»ƒæ¨¡å‹
            model.fit(X_train, y_train)
            
            # é¢„æµ‹
            y_pred = model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            
            # äº¤å‰éªŒè¯
            cv_scores = cross_val_score(model, X_train, y_train, cv=3)
            
            # ä¿å­˜ç»“æœ
            results[name] = {
                'model': model,
                'accuracy': accuracy,
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std()
            }
            
            # ä¿å­˜æ¨¡å‹
            self.models[name] = model
            
            print(f"{name} - å‡†ç¡®ç‡: {accuracy:.4f}, äº¤å‰éªŒè¯: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
            
            # æ›´æ–°æœ€ä½³æ¨¡å‹
            if cv_scores.mean() > self.best_score:
                self.best_score = cv_scores.mean()
                self.best_model = name
        
        print(f"\næœ€ä½³æ¨¡å‹: {self.best_model} (äº¤å‰éªŒè¯å¾—åˆ†: {self.best_score:.4f})")
        
        return results, X_test, y_test
    
    def save_models(self):
        """ä¿å­˜æ¨¡å‹"""
        os.makedirs('static/models', exist_ok=True)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        best_model = self.models[self.best_model]
        joblib.dump(best_model, 'static/models/advanced_traffic_model.pkl')
        
        # ä¿å­˜ç¼–ç å™¨å’Œç¼©æ”¾å™¨
        joblib.dump(self.scalers, 'static/models/categorical_encoders.pkl')
        joblib.dump(self.label_encoder, 'static/models/label_encoder.pkl')
        
        # å•ç‹¬ä¿å­˜ç‰¹å¾ç¼©æ”¾å™¨
        if 'feature_scaler' in self.scalers:
            joblib.dump(self.scalers['feature_scaler'], 'static/models/feature_scaler.pkl')
        
        # ä¿å­˜æ¨¡å‹ä¿¡æ¯
        model_info = {
            'best_model': self.best_model,
            'best_score': self.best_score,
            'feature_names': getattr(self, 'feature_names', []),
            'accuracy': self.best_score,
            'classes': self.label_encoder.classes_.tolist()
        }
        joblib.dump(model_info, 'static/models/model_info.pkl')
        
        print(f"æ¨¡å‹å·²ä¿å­˜åˆ° static/models/")

def main(data_size=10000, use_existing_data=False):
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒé«˜çº§ç½‘ç»œæµé‡åˆ†ç±»æ¨¡å‹")
    print("=" * 50)
    
    # 1. ç”Ÿæˆæˆ–åŠ è½½æ•°æ®
    if use_existing_data and os.path.exists('traffic_training_data.csv'):
        print("ğŸ“Š ä½¿ç”¨ç°æœ‰è®­ç»ƒæ•°æ®...")
        classifier = AdvancedTrafficClassifier()
        df = classifier.load_and_preprocess_data('traffic_training_data.csv')
    else:
        print("ğŸ“Š ç”Ÿæˆæ–°çš„è®­ç»ƒæ•°æ®...")
        generator = TrafficDataGenerator()
        dataset = generator.generate_dataset(data_size)
        dataset.to_csv('traffic_training_data.csv', index=False)
        
        # 2. è®­ç»ƒé«˜çº§æ¨¡å‹
        classifier = AdvancedTrafficClassifier()
        df = classifier.load_and_preprocess_data(df=dataset)
    
    print("\nğŸ¤– åˆå§‹åŒ–é«˜çº§åˆ†ç±»å™¨")
    
    # 3. å‡†å¤‡ç‰¹å¾
    print("ğŸ”§ æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹...")
    X, feature_names = classifier.prepare_features(df)
    classifier.feature_names = feature_names
    
    # ç¼–ç æ ‡ç­¾
    y = classifier.label_encoder.fit_transform(df['label'])
    
    print(f"ç‰¹å¾ç»´åº¦: {X.shape}")
    print(f"ç±»åˆ«åˆ†å¸ƒ: {dict(zip(classifier.label_encoder.classes_, np.bincount(y)))}")
    
    # 4. è®­ç»ƒæ¨¡å‹
    print("\nğŸ¯ è®­ç»ƒå¤šç§æœºå™¨å­¦ä¹ æ¨¡å‹...")
    results, X_test, y_test = classifier.train_models(X, y)
    
    # 5. ä¿å­˜æ¨¡å‹
    print("\nğŸ’¾ ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹...")
    classifier.save_models()
    
    print("\nğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    print("=" * 50)
    print(f"æœ€ä½³æ¨¡å‹: {classifier.best_model}")
    print(f"äº¤å‰éªŒè¯å¾—åˆ†: {classifier.best_score:.4f}")
    print("æ¨¡å‹æ–‡ä»¶ä¿å­˜åœ¨: static/models/")
    
    return classifier

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='è®­ç»ƒç½‘ç»œæµé‡åˆ†ç±»æ¨¡å‹')
    parser.add_argument('--size', type=int, default=10000, help='è®­ç»ƒæ•°æ®å¤§å° (é»˜è®¤: 10000)')
    parser.add_argument('--use-existing', action='store_true', help='ä½¿ç”¨ç°æœ‰çš„è®­ç»ƒæ•°æ®æ–‡ä»¶')
    
    args = parser.parse_args()
    
    main(data_size=args.size, use_existing_data=args.use_existing)